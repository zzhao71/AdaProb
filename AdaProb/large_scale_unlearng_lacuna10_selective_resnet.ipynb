{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16127/3351334044.py:20: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import variational\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "import copy\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from typing import List\n",
    "import itertools\n",
    "from tqdm.autonotebook import tqdm\n",
    "from models import *\n",
    "import models\n",
    "from logger import *\n",
    "import wandb\n",
    "\n",
    "from thirdparty.repdistiller.helper.util import adjust_learning_rate as sgda_adjust_learning_rate\n",
    "from thirdparty.repdistiller.distiller_zoo import DistillKL, HintLoss, Attention, Similarity, Correlation, VIDLoss, RKDLoss\n",
    "from thirdparty.repdistiller.distiller_zoo import PKT, ABLoss, FactorTransfer, KDSVD, FSP, NSTLoss\n",
    "\n",
    "from thirdparty.repdistiller.helper.loops import train_distill, train_distill_hide, train_distill_linear, train_vanilla, train_negrad, train_bcu, train_bcu_distill, validate\n",
    "from thirdparty.repdistiller.helper.pretrain import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdb():\n",
    "    import pdb\n",
    "    pdb.set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_count(model):\n",
    "    count=0\n",
    "    for p in model.parameters():\n",
    "        count+=np.prod(np.array(list(p.shape)))\n",
    "    print(f'Total Number of Parameters: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_params(model):\n",
    "    param = []\n",
    "    for p in model.parameters():\n",
    "        param.append(p.data.view(-1).cpu().numpy())\n",
    "    return np.concatenate(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_param_shape(model):\n",
    "    for k,p in model.named_parameters():\n",
    "        print(k,p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Activations along the path\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import datasets\n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return TP, FP, TN, FN\n",
    "\n",
    "def entropy(p, dim = -1, keepdim = False):\n",
    "    return -torch.where(p > 0, p * p.log(), p.new([0.0])).sum(dim=dim, keepdim=keepdim)\n",
    "    #return (p * p.log()).sum(dim=dim, keepdim=keepdim)\n",
    "\n",
    "def collect_prob(data_loader, model):\n",
    "    data_loader = torch.utils.data.DataLoader(data_loader.dataset, batch_size=1, shuffle=False)\n",
    "    sampler = torch.utils.data.RandomSampler(data_loader.dataset, replacement=False, num_samples=4000)\n",
    "    data_loader_small = torch.utils.data.DataLoader(data_loader.dataset, batch_size=1, sampler=sampler, shuffle=False)\n",
    "    prob = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(tqdm(data_loader_small, leave=False)):\n",
    "            batch = [tensor.to(next(model.parameters()).device) for tensor in batch]\n",
    "            data, target = batch\n",
    "            output = model(data)\n",
    "            prob.append(F.softmax(output, dim=-1).data)\n",
    "    return torch.cat(prob)\n",
    "\n",
    "def get_membership_attack_data(retain_loader, forget_loader, test_loader, model):    \n",
    "    retain_prob = collect_prob(retain_loader, model)\n",
    "    forget_prob = collect_prob(forget_loader, model)\n",
    "    test_prob = collect_prob(test_loader, model)\n",
    "    \n",
    "    X_r = torch.cat([entropy(retain_prob), entropy(test_prob)]).cpu().numpy().reshape(-1, 1)\n",
    "    Y_r = np.concatenate([np.ones(len(retain_prob)), np.zeros(len(test_prob))])\n",
    "    \n",
    "    X_f = entropy(forget_prob).cpu().numpy().reshape(-1, 1)\n",
    "    Y_f = np.concatenate([np.ones(len(forget_prob))])    \n",
    "    return X_f, Y_f, X_r, Y_r\n",
    "\n",
    "def get_membership_attack_prob(retain_loader, forget_loader, test_loader, model):\n",
    "    X_f, Y_f, X_r, Y_r = get_membership_attack_data(retain_loader, forget_loader, test_loader, model)\n",
    "    #clf = SVC(C=3,gamma='auto',kernel='rbf')\n",
    "    clf = LogisticRegression(class_weight='balanced',solver='lbfgs',multi_class='multinomial')\n",
    "    clf.fit(X_r, Y_r)\n",
    "    results = clf.predict(X_f)\n",
    "    results1 = clf.predict(X_r)\n",
    "    acc = accuracy_score(results, Y_f)\n",
    "    train_ac = accuracy_score(results1, Y_r)\n",
    "    TP, FP, TN, FN = perf_measure(Y_r, results1)\n",
    "    FPR = FP/(FP+TN)\n",
    "    FNR = FN/(FN+TP)\n",
    "    \n",
    "    print (f\"TP:{TP}, FP{FP}, TN{TN}, FN{FN}\")\n",
    "    print (f\"false negative rate: {FN/(FN+TP)}\")\n",
    "    print (f\"false positive rate: {FP/(FP+TN)}\")\n",
    "    return acc, train_acc, FPR, FNR #results.mean(), results1.mean()\n",
    "    \n",
    "def plot_entropy_dist(model,retain_loader,forget_loader,test_loader_full, title, ax):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from matplotlib.ticker import FuncFormatter\n",
    "    #train_loader_full, valid_loader_full, test_loader_full = datasets.get_loaders(dataset, batch_size=100, seed=0, augment=False, shuffle=False)\n",
    "    #indexes = np.flatnonzero(np.array(train_loader_full.dataset.targets) == class_to_forget)\n",
    "    #replaced = np.random.RandomState(0).choice(indexes, size=100 if num_to_forget==100 else len(indexes), replace=False)\n",
    "    X_f, Y_f, X_r, Y_r = get_membership_attack_data(retain_loader,forget_loader,test_loader_full, model)\n",
    "    #np.savetxt('retain_prob.txt', X_r[Y_r==1])\n",
    "    #np.savetxt('forget_prob.txt', X_f)\n",
    "    #np.savetxt('test_prob.txt', X_r[Y_r==0])\n",
    "    sns.distplot(np.log(X_r[Y_r==1]).reshape(-1), kde=False, norm_hist=True, rug=False, label='retain', ax=plt)\n",
    "    sns.distplot(np.log(X_r[Y_r==0]).reshape(-1), kde=False, norm_hist=True, rug=False, label='test', ax=plt)\n",
    "    sns.distplot(np.log(X_f).reshape(-1), kde=False, norm_hist=True, rug=False, label='forget', ax=plt)\n",
    "    plt.legend(prop={'size': 14})\n",
    "    plt.tick_params(labelsize=12)\n",
    "    plt.title(title,size=18)\n",
    "    plt.xlabel('Log of Entropy',size=14)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "def membership_attack(retain_loader,forget_loader,test_loader,model, name):\n",
    "    prob, train_acc, FPR, FNR = get_membership_attack_prob(retain_loader,forget_loader,test_loader,model)\n",
    "    print(\"Attack prob: \", prob)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "def get_metrics(model,dataloader,criterion,samples_correctness=False,use_bn=False,delta_w=None,scrub_act=False):\n",
    "    activations=[]\n",
    "    predictions=[]\n",
    "    if use_bn:\n",
    "        model.train()\n",
    "        dataloader = torch.utils.data.DataLoader(retain_loader.dataset, batch_size=512, shuffle=True)\n",
    "        for i in range(10):\n",
    "            for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                data, target = data.to(args.device), target.to(args.device)            \n",
    "                output = model(data)\n",
    "    dataloader = torch.utils.data.DataLoader(dataloader.dataset, batch_size=512, shuffle=False)\n",
    "    model.eval()\n",
    "    metrics = AverageMeter()\n",
    "    mult = 0.5 if args.lossfn=='mse' else 1\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        data, target = data.to(args.device), target.to(args.device)            \n",
    "        if args.lossfn=='mse':\n",
    "            target=(2*target-1)\n",
    "            target = target.type(torch.cuda.FloatTensor).unsqueeze(1)\n",
    "        if 'mnist' in args.dataset:\n",
    "            data=data.view(data.shape[0],-1)\n",
    "        output = model(data)\n",
    "        loss = mult*criterion(output, target)\n",
    "        if samples_correctness:\n",
    "            activations.append(torch.nn.functional.softmax(output,dim=1).cpu().detach().numpy().squeeze())\n",
    "            predictions.append(get_error(output,target))\n",
    "        metrics.update(n=data.size(0), loss=loss.item(), error=get_error(output, target))\n",
    "    if samples_correctness:\n",
    "        return metrics.avg,np.stack(activations),np.array(predictions)\n",
    "    else:\n",
    "        return metrics.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activations_predictions(model,dataloader,name):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    metrics=get_metrics(model,dataloader,criterion,False)\n",
    "    print(f\"{name} -> Loss:{np.round(metrics['loss'],3)}, Error:{metrics['error']}\")\n",
    "    log_dict[f\"{name}_loss\"]=metrics['loss']\n",
    "    log_dict[f\"{name}_error\"]=metrics['error']\n",
    "    return _,_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_distance(l1,l2,name):\n",
    "    dist = np.sum(np.abs(l1-l2))\n",
    "    print(f\"Predictions Distance {name} -> {dist}\")\n",
    "    log_dict[f\"{name}_predictions\"]=dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activations_distance(a1,a2,name):\n",
    "    dist = np.linalg.norm(a1-a2,ord=1,axis=1).mean()\n",
    "    print(f\"Activations Distance {name} -> {dist}\")\n",
    "    log_dict[f\"{name}_activations\"]=dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "def get_metrics(model,dataloader,criterion,samples_correctness=False,use_bn=False,delta_w=None,scrub_act=False):\n",
    "    activations=[]\n",
    "    predictions=[]\n",
    "    if use_bn:\n",
    "        model.train()\n",
    "        dataloader = torch.utils.data.DataLoader(retain_loader.dataset, batch_size=128, shuffle=True)\n",
    "        for i in range(10):\n",
    "            for batch_idx, (data, target) in enumerate(dataloader):\n",
    "                data, target = data.to(args.device), target.to(args.device)            \n",
    "                output = model(data)\n",
    "    dataloader = torch.utils.data.DataLoader(dataloader.dataset, batch_size=1, shuffle=False)\n",
    "    model.eval()\n",
    "    metrics = AverageMeter()\n",
    "    mult = 0.5 if args.lossfn=='mse' else 1\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        data, target = data.to(args.device), target.to(args.device)            \n",
    "        if args.lossfn=='mse':\n",
    "            target=(2*target-1)\n",
    "            target = target.type(torch.cuda.FloatTensor).unsqueeze(1)\n",
    "        if 'mnist' in args.dataset:\n",
    "            data=data.view(data.shape[0],-1)\n",
    "        output = model(data)\n",
    "        if scrub_act:\n",
    "            G = []\n",
    "            for cls in range(num_classes):\n",
    "                grads = torch.autograd.grad(output[0,cls],model.parameters(),retain_graph=True)\n",
    "                grads = torch.cat([g.view(-1) for g in grads])\n",
    "                G.append(grads)\n",
    "            grads = torch.autograd.grad(output_sf[0,cls],model_scrubf.parameters(),retain_graph=False)\n",
    "            G = torch.stack(G).pow(2)\n",
    "            delta_f = torch.matmul(G,delta_w)\n",
    "            output += delta_f.sqrt()*torch.empty_like(delta_f).normal_()\n",
    "\n",
    "        loss = mult*criterion(output, target)\n",
    "        if samples_correctness:\n",
    "            activations.append(torch.nn.functional.softmax(output,dim=1).cpu().detach().numpy().squeeze())\n",
    "            predictions.append(get_error(output,target))\n",
    "        metrics.update(n=data.size(0), loss=loss.item(), error=get_error(output, target))\n",
    "    if samples_correctness:\n",
    "        return metrics.avg,np.stack(activations),np.array(predictions)\n",
    "    else:\n",
    "        return metrics.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_penalty(model,model_init,weight_decay):\n",
    "    l2_loss = 0\n",
    "    for (k,p),(k_init,p_init) in zip(model.named_parameters(),model_init.named_parameters()):\n",
    "        if p.requires_grad:\n",
    "            l2_loss += (p-p_init).pow(2).sum()\n",
    "    l2_loss *= (weight_decay/2.)\n",
    "    return l2_loss\n",
    "\n",
    "def run_train_epoch(model: nn.Module, model_init, data_loader: torch.utils.data.DataLoader, \n",
    "                    loss_fn: nn.Module,\n",
    "                    optimizer: torch.optim.SGD, split: str, epoch: int, ignore_index=None,\n",
    "                    negative_gradient=False, negative_multiplier=-1, random_labels=False,\n",
    "                    quiet=False,delta_w=None,scrub_act=False):\n",
    "    model.eval()\n",
    "    metrics = AverageMeter()    \n",
    "    num_labels = data_loader.dataset.targets.max().item() + 1\n",
    "    \n",
    "    with torch.set_grad_enabled(split != 'test'):\n",
    "        for idx, batch in enumerate(tqdm(data_loader, leave=False)):\n",
    "            batch = [tensor.to(next(model.parameters()).device) for tensor in batch]\n",
    "            input, target = batch\n",
    "            output = model(input)\n",
    "            if split=='test' and scrub_act:\n",
    "                G = []\n",
    "                for cls in range(num_classes):\n",
    "                    grads = torch.autograd.grad(output[0,cls],model.parameters(),retain_graph=True)\n",
    "                    grads = torch.cat([g.view(-1) for g in grads])\n",
    "                    G.append(grads)\n",
    "                grads = torch.autograd.grad(output_sf[0,cls],model_scrubf.parameters(),retain_graph=False)\n",
    "                G = torch.stack(G).pow(2)\n",
    "                delta_f = torch.matmul(G,delta_w)\n",
    "                output += delta_f.sqrt()*torch.empty_like(delta_f).normal_()\n",
    "            loss = loss_fn(output, target) + l2_penalty(model,model_init,args.weight_decay)\n",
    "            metrics.update(n=input.size(0), loss=loss_fn(output,target).item(), error=get_error(output, target))\n",
    "            \n",
    "            if split != 'test':\n",
    "                model.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    if not quiet:\n",
    "        log_metrics(split, metrics, epoch)\n",
    "    return metrics.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune(model: nn.Module, data_loader: torch.utils.data.DataLoader, lr=0.01, epochs=10, quiet=False):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=0)\n",
    "    model_init=copy.deepcopy(model)\n",
    "    for epoch in range(epochs):\n",
    "        #run_train_epoch(model, model_init, data_loader, loss_fn, optimizer, split='train', epoch=epoch, ignore_index=None, quiet=quiet)\n",
    "        train_vanilla(epoch, data_loader, model, loss_fn, optimizer, args)\n",
    "\n",
    "def test(model, data_loader):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    model_init=copy.deepcopy(model)\n",
    "    return run_train_epoch(model, model_init, data_loader, loss_fn, optimizer=None, split='test', epoch=epoch, ignore_index=None, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readout_retrain(model, data_loader, test_loader, lr=0.1, epochs=500, threshold=0.01, quiet=True):\n",
    "    torch.manual_seed(seed)\n",
    "    model = copy.deepcopy(model)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=0.0)\n",
    "    sampler = torch.utils.data.RandomSampler(data_loader.dataset, replacement=True, num_samples=500)\n",
    "    data_loader_small = torch.utils.data.DataLoader(data_loader.dataset, batch_size=data_loader.batch_size, sampler=sampler, num_workers=data_loader.num_workers)\n",
    "    metrics = []\n",
    "    model_init=copy.deepcopy(model)\n",
    "    for epoch in range(epochs):\n",
    "        metrics.append(run_train_epoch(model, model_init, test_loader, loss_fn, optimizer, split='test', epoch=epoch, ignore_index=None, quiet=quiet))\n",
    "        if metrics[-1]['loss'] <= threshold:\n",
    "            break\n",
    "        run_train_epoch(model, model_init, data_loader_small, loss_fn, optimizer, split='train', epoch=epoch, ignore_index=None, quiet=quiet)\n",
    "    return epoch, metrics\n",
    "\n",
    "def extract_retrain_time(metrics, threshold=0.1):\n",
    "    losses = np.array([m['loss'] for m in metrics])\n",
    "    return np.argmax(losses < threshold)\n",
    "\n",
    "def all_readouts(model,thresh=0.1,name='method'):\n",
    "    train_loader = torch.utils.data.DataLoader(train_loader_full.dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    retrain_time, _ = readout_retrain(model, train_loader, forget_loader, epochs=100, lr=0.01, threshold=thresh)\n",
    "    test_error = test(model, test_loader_full)['error']\n",
    "    forget_error = test(model, forget_loader)['error']\n",
    "    retain_error = test(model, retain_loader)['error']\n",
    "    print(f\"{name} ->\"\n",
    "          f\"\\tFull test error: {test_error:.2%}\"\n",
    "          f\"\\tForget error: {forget_error:.2%}\\tRetain error: {retain_error:.2%}\"\n",
    "          f\"\\tFine-tune time: {retrain_time+1} steps\")\n",
    "    #print(f\"{name} ->\"\n",
    "    #      f\"\\tFine-tune time: {retrain_time+1} steps\")\n",
    "    log_dict[f\"{name}_retrain_time\"]=retrain_time+1\n",
    "    return(dict(test_error=test_error, forget_error=forget_error, retain_error=retain_error, retrain_time=retrain_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_activations(model_scrubf, modelf0, delta_w_s, delta_w_m0, data_loader, \\\n",
    "                    loss_fn=nn.CrossEntropyLoss(),\\\n",
    "                    optimizer=torch.optim.SGD, \\\n",
    "                    seed=1,quiet=False):\n",
    "\n",
    "    model_scrubf.eval()\n",
    "    modelf0.eval()\n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(data_loader.dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    \n",
    "    metrics = AverageMeter()    \n",
    "    num_classes = data_loader.dataset.targets.max().item() + 1\n",
    "    \n",
    "    for idx, batch in enumerate(tqdm(data_loader, leave=False)):\n",
    "        batch = [tensor.to(next(model_scrubf.parameters()).device) for tensor in batch]\n",
    "        input, target = batch\n",
    "        \n",
    "        output_sf = model_scrubf(input)\n",
    "        G_sf = []\n",
    "\n",
    "        for cls in range(num_classes):\n",
    "            grads = torch.autograd.grad(output_sf[0,cls],model_scrubf.parameters(),retain_graph=True)\n",
    "            grads = torch.cat([g.view(-1) for g in grads])\n",
    "            G_sf.append(grads)\n",
    "\n",
    "        grads = torch.autograd.grad(output_sf[0,cls],model_scrubf.parameters(),retain_graph=False)\n",
    "            \n",
    "        G_sf = torch.stack(G_sf)#.pow(2)\n",
    "        delta_f_sf_update = torch.matmul(G_sf,delta_w_s.sqrt()*torch.empty_like(delta_w_s).normal_())\n",
    "        G_sf = G_sf.pow(2)\n",
    "        delta_f_sf = torch.matmul(G_sf,delta_w_s)\n",
    "\n",
    "        output_m0 = modelf0(input)\n",
    "        G_m0 = []\n",
    "\n",
    "        for cls in range(num_classes):\n",
    "            grads = torch.autograd.grad(output_m0[0,cls],modelf0.parameters(),retain_graph=True)\n",
    "            grad_m0 = torch.cat([g.view(-1) for g in grads])\n",
    "            G_m0.append(grad_m0)\n",
    "\n",
    "        grads = torch.autograd.grad(output_m0[0,cls],modelf0.parameters(),retain_graph=False)\n",
    "            \n",
    "        G_m0 = torch.stack(G_m0).pow(2)\n",
    "        delta_f_m0 = torch.matmul(G_m0,delta_w_m0)\n",
    "        \n",
    "        kl = ((output_m0 - output_sf).pow(2)/delta_f_m0 + delta_f_sf/delta_f_m0 - torch.log(delta_f_sf/delta_f_m0) - 1).sum()\n",
    "        \n",
    "        torch.manual_seed(seed)\n",
    "        output_sf += delta_f_sf_update#delta_f_sf.sqrt()*torch.empty_like(delta_f_sf).normal_()\n",
    "        \n",
    "        loss = loss_fn(output_sf, target)\n",
    "        metrics.update(n=input.size(0), loss=loss.item(), error=get_error(output_sf, target), kl=kl.item())\n",
    "    \n",
    "    return metrics.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint name: lacuna100_resnet_1_0_forget_None_lr_0_1_bs_128_ls_ce_wd_0_0005_seed_1\n",
      "[Logging in lacuna100_resnet_1_0_forget_None_lr_0_1_bs_128_ls_ce_wd_0_0005_seed_1_training]\n",
      "confuse mode: False\n",
      "split mode: None\n",
      "Number of Classes: 100\n",
      "[0] train metrics:{\"loss\": 3.987484888076782, \"error\": 0.923}\n",
      "Learning Rate : 0.1\n",
      "[0] dry_run metrics:{\"loss\": 3.395326801300049, \"error\": 0.83653125}\n",
      "Learning Rate : 0.1\n",
      "[0] test metrics:{\"loss\": 3.4219942169189452, \"error\": 0.8447}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 15.48 sec\n",
      "[1] train metrics:{\"loss\": 3.1922737522125244, \"error\": 0.78334375}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 9.08 sec\n",
      "[2] train metrics:{\"loss\": 2.6385717277526854, \"error\": 0.63821875}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 8.98 sec\n",
      "[3] train metrics:{\"loss\": 2.220917667865753, \"error\": 0.51859375}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 8.92 sec\n",
      "[4] train metrics:{\"loss\": 1.9556603002548218, \"error\": 0.41671875}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 5.76 sec\n",
      "[5] train metrics:{\"loss\": 1.722495491027832, \"error\": 0.32259375}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 5.42 sec\n",
      "[6] train metrics:{\"loss\": 1.5956408495903016, \"error\": 0.26075}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 5.46 sec\n",
      "[7] train metrics:{\"loss\": 1.567377972126007, \"error\": 0.22371875}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 5.5 sec\n",
      "[8] train metrics:{\"loss\": 1.5533827967643739, \"error\": 0.1940625}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 5.41 sec\n",
      "[9] train metrics:{\"loss\": 1.523199393749237, \"error\": 0.16503125}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 5.42 sec\n",
      "[10] train metrics:{\"loss\": 1.531425853729248, \"error\": 0.150625}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 5.48 sec\n",
      "[11] train metrics:{\"loss\": 1.521689467906952, \"error\": 0.1343125}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 5.41 sec\n",
      "[12] train metrics:{\"loss\": 1.5069730429649353, \"error\": 0.1225625}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 5.41 sec\n",
      "[13] train metrics:{\"loss\": 1.5114346590042114, \"error\": 0.12234375}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 5.38 sec\n",
      "[14] train metrics:{\"loss\": 1.517757547855377, \"error\": 0.1201875}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 5.37 sec\n",
      "[15] train metrics:{\"loss\": 1.5435997090339661, \"error\": 0.1189375}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 5.5 sec\n",
      "[16] train metrics:{\"loss\": 1.5590977020263672, \"error\": 0.11846875}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 5.39 sec\n",
      "[17] train metrics:{\"loss\": 1.543018394470215, \"error\": 0.10815625}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 5.61 sec\n",
      "[18] train metrics:{\"loss\": 1.5397232418060303, \"error\": 0.10703125}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 6.03 sec\n",
      "[19] train metrics:{\"loss\": 1.5722574791908264, \"error\": 0.11421875}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 6.35 sec\n",
      "[20] train metrics:{\"loss\": 1.5940280084609986, \"error\": 0.1075}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 6.85 sec\n",
      "[21] train metrics:{\"loss\": 1.5399379086494447, \"error\": 0.0955625}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 6.52 sec\n",
      "[22] train metrics:{\"loss\": 1.5899784002304078, \"error\": 0.1098125}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 6.28 sec\n",
      "[23] train metrics:{\"loss\": 1.6024198775291443, \"error\": 0.1053125}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 6.15 sec\n",
      "[24] train metrics:{\"loss\": 1.549412570476532, \"error\": 0.09359375}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 6.23 sec\n",
      "[25] train metrics:{\"loss\": 1.580799273967743, \"error\": 0.1025}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 5.54 sec\n",
      "[26] train metrics:{\"loss\": 1.577813358783722, \"error\": 0.10015625}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 6.31 sec\n",
      "[27] train metrics:{\"loss\": 1.5733731870651244, \"error\": 0.09746875}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 6.37 sec\n",
      "[28] train metrics:{\"loss\": 1.586123302936554, \"error\": 0.10090625}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 6.34 sec\n",
      "[29] train metrics:{\"loss\": 1.5767607717514038, \"error\": 0.094625}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 6.4 sec\n",
      "[30] train metrics:{\"loss\": 1.5994566655158997, \"error\": 0.1015}\n",
      "Learning Rate : 0.1\n",
      "Epoch Time: 6.49 sec\n",
      "Pure training time: 194.47000000000003 sec\n"
     ]
    }
   ],
   "source": [
    "%run main.py --dataset lacuna100 --dataroot=data/lacuna100 --model resnet --filters 1.0 --lr 0.1 --lossfn ce --num-classes 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint name: lacuna10_resnet_1_0_forget_None_lr_0_01_bs_128_ls_ce_wd_0_0005_seed_1\n",
      "[Logging in lacuna10_resnet_1_0_forget_None_lr_0_01_bs_128_ls_ce_wd_0_0005_seed_1_training]\n",
      "confuse mode: False\n",
      "split mode: train\n",
      "Number of Classes: 10\n",
      "Epoch: [0][0/25]\tTime 0.036 (0.036)\tData 0.007 (0.007)\tLoss 0.8869 (0.8869)\tAcc@1 87.500 (87.500)\tAcc@5 99.219 (99.219)\n",
      " * Acc@1 90.781 Acc@5 99.000\n",
      "[0] test metrics:{\"loss\": 0.20946366262435914, \"error\": 0.055999995708465575}\n",
      "Learning Rate : 0.01\n",
      "Epoch Time: 0.61 sec\n",
      "Epoch: [1][0/25]\tTime 0.014 (0.014)\tData 0.007 (0.007)\tLoss 0.1985 (0.1985)\tAcc@1 92.969 (92.969)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 95.500 Acc@5 99.750\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [2][0/25]\tTime 0.015 (0.015)\tData 0.006 (0.006)\tLoss 0.0561 (0.0561)\tAcc@1 99.219 (99.219)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 98.250 Acc@5 99.969\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [3][0/25]\tTime 0.015 (0.015)\tData 0.006 (0.006)\tLoss 0.0369 (0.0369)\tAcc@1 99.219 (99.219)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 99.469 Acc@5 100.000\n",
      "Epoch Time: 0.44 sec\n",
      "Epoch: [4][0/25]\tTime 0.014 (0.014)\tData 0.006 (0.006)\tLoss 0.0171 (0.0171)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 99.812 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [5][0/25]\tTime 0.014 (0.014)\tData 0.006 (0.006)\tLoss 0.0164 (0.0164)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 99.969 Acc@5 100.000\n",
      "[5] test metrics:{\"loss\": 0.11269214117527009, \"error\": 0.030999996662139893}\n",
      "Learning Rate : 0.01\n",
      "Epoch Time: 0.58 sec\n",
      "Epoch: [6][0/25]\tTime 0.017 (0.017)\tData 0.007 (0.007)\tLoss 0.0156 (0.0156)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 99.969 Acc@5 100.000\n",
      "Epoch Time: 0.44 sec\n",
      "Epoch: [7][0/25]\tTime 0.014 (0.014)\tData 0.006 (0.006)\tLoss 0.0074 (0.0074)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 99.969 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [8][0/25]\tTime 0.015 (0.015)\tData 0.006 (0.006)\tLoss 0.0066 (0.0066)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [9][0/25]\tTime 0.014 (0.014)\tData 0.007 (0.007)\tLoss 0.0062 (0.0062)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.42 sec\n",
      "Epoch: [10][0/25]\tTime 0.014 (0.014)\tData 0.007 (0.007)\tLoss 0.0055 (0.0055)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "[10] test metrics:{\"loss\": 0.1133830133676529, \"error\": 0.030999996662139893}\n",
      "Learning Rate : 0.01\n",
      "Epoch Time: 0.59 sec\n",
      "Epoch: [11][0/25]\tTime 0.015 (0.015)\tData 0.007 (0.007)\tLoss 0.0038 (0.0038)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [12][0/25]\tTime 0.015 (0.015)\tData 0.006 (0.006)\tLoss 0.0031 (0.0031)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [13][0/25]\tTime 0.015 (0.015)\tData 0.007 (0.007)\tLoss 0.0025 (0.0025)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.42 sec\n",
      "Epoch: [14][0/25]\tTime 0.015 (0.015)\tData 0.007 (0.007)\tLoss 0.0040 (0.0040)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [15][0/25]\tTime 0.014 (0.014)\tData 0.007 (0.007)\tLoss 0.0024 (0.0024)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "[15] test metrics:{\"loss\": 0.11351716929674148, \"error\": 0.029999996662139893}\n",
      "Learning Rate : 0.01\n",
      "Epoch Time: 0.59 sec\n",
      "Epoch: [16][0/25]\tTime 0.016 (0.016)\tData 0.007 (0.007)\tLoss 0.0025 (0.0025)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [17][0/25]\tTime 0.015 (0.015)\tData 0.007 (0.007)\tLoss 0.0029 (0.0029)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [18][0/25]\tTime 0.015 (0.015)\tData 0.007 (0.007)\tLoss 0.0023 (0.0023)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [19][0/25]\tTime 0.016 (0.016)\tData 0.006 (0.006)\tLoss 0.0021 (0.0021)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [20][0/25]\tTime 0.015 (0.015)\tData 0.006 (0.006)\tLoss 0.0020 (0.0020)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "[20] test metrics:{\"loss\": 0.11552823621034622, \"error\": 0.02899999666213989}\n",
      "Learning Rate : 0.01\n",
      "Epoch Time: 0.58 sec\n",
      "Epoch: [21][0/25]\tTime 0.014 (0.014)\tData 0.007 (0.007)\tLoss 0.0028 (0.0028)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.42 sec\n",
      "Epoch: [22][0/25]\tTime 0.013 (0.013)\tData 0.006 (0.006)\tLoss 0.0016 (0.0016)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.42 sec\n",
      "Epoch: [23][0/25]\tTime 0.016 (0.016)\tData 0.007 (0.007)\tLoss 0.0015 (0.0015)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [24][0/25]\tTime 0.014 (0.014)\tData 0.007 (0.007)\tLoss 0.0011 (0.0011)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.44 sec\n",
      "Epoch: [25][0/25]\tTime 0.015 (0.015)\tData 0.007 (0.007)\tLoss 0.0014 (0.0014)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "[25] test metrics:{\"loss\": 0.11844244855642319, \"error\": 0.027999996662139894}\n",
      "Learning Rate : 0.01\n",
      "Epoch Time: 0.58 sec\n",
      "Pure training time: 11.199999999999998 sec\n"
     ]
    }
   ],
   "source": [
    "%run main_merged.py --dataset lacuna10 --model resnet --dataroot=data/lacuna10/ --filters 1.0 --lr 0.01 \\\n",
    "--resume checkpoints/lacuna100_resnet_1_0_forget_None_lr_0_1_bs_128_ls_ce_wd_0_0005_seed_1_30.pt --disable-bn \\\n",
    "--weight-decay 5e-4 --batch-size 128 --epochs 26 --seed 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Forgetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint name: lacuna10_resnet_1_0_forget_[5]_num_100_lr_0_01_bs_128_ls_ce_wd_0_0005_seed_1\n",
      "[Logging in lacuna10_resnet_1_0_forget_[5]_num_100_lr_0_01_bs_128_ls_ce_wd_0_0005_seed_1_training]\n",
      "confuse mode: False\n",
      "split mode: train\n",
      "Replacing indexes [1781 1858 1615 1665 1816 1663 1840 1828 1767 1756 1664 1703 1724 1915\n",
      " 1910 1660 1722 1871 1666 1626 1886 1758 1736 1909 1764 1800 1872 1607\n",
      " 1606 1830 1854 1622 1752 1621 1655 1757 1612 1708 1668 1744 1770 1878\n",
      " 1659 1734 1831 1692 1775 1867 1674 1681 1888 1859 1864 1652 1733 1776\n",
      " 1656 1690 1848 1617 1601 1608 1750 1806 1809 1740 1817 1794 1605 1633\n",
      " 1880 1634 1812 1815 1863 1737 1645 1701 1866 1726 1798 1838 1799 1822\n",
      " 1720 1845 1735 1673 1913 1904 1716 1855 1629 1697 1620 1646 1813 1862\n",
      " 1912 1689]\n",
      "Number of Classes: 10\n",
      "Epoch: [0][0/25]\tTime 0.018 (0.018)\tData 0.006 (0.006)\tLoss 0.8943 (0.8943)\tAcc@1 85.156 (85.156)\tAcc@5 99.219 (99.219)\n",
      " * Acc@1 90.688 Acc@5 99.062\n",
      "[0] test metrics:{\"loss\": 0.21211926794052124, \"error\": 0.05899999570846558}\n",
      "Learning Rate : 0.01\n",
      "Epoch Time: 0.58 sec\n",
      "Epoch: [1][0/25]\tTime 0.015 (0.015)\tData 0.008 (0.008)\tLoss 0.1813 (0.1813)\tAcc@1 93.750 (93.750)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 95.625 Acc@5 99.781\n",
      "Epoch Time: 0.44 sec\n",
      "Epoch: [2][0/25]\tTime 0.016 (0.016)\tData 0.007 (0.007)\tLoss 0.0534 (0.0534)\tAcc@1 99.219 (99.219)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 98.312 Acc@5 99.969\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [3][0/25]\tTime 0.016 (0.016)\tData 0.006 (0.006)\tLoss 0.0360 (0.0360)\tAcc@1 99.219 (99.219)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 99.469 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [4][0/25]\tTime 0.016 (0.016)\tData 0.006 (0.006)\tLoss 0.0168 (0.0168)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 99.781 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [5][0/25]\tTime 0.015 (0.015)\tData 0.007 (0.007)\tLoss 0.0153 (0.0153)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 99.969 Acc@5 100.000\n",
      "[5] test metrics:{\"loss\": 0.1146538815498352, \"error\": 0.029999996662139893}\n",
      "Learning Rate : 0.01\n",
      "Epoch Time: 0.59 sec\n",
      "Epoch: [6][0/25]\tTime 0.016 (0.016)\tData 0.007 (0.007)\tLoss 0.0151 (0.0151)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 99.969 Acc@5 100.000\n",
      "Epoch Time: 0.44 sec\n",
      "Epoch: [7][0/25]\tTime 0.016 (0.016)\tData 0.007 (0.007)\tLoss 0.0070 (0.0070)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 99.969 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [8][0/25]\tTime 0.015 (0.015)\tData 0.007 (0.007)\tLoss 0.0057 (0.0057)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.44 sec\n",
      "Epoch: [9][0/25]\tTime 0.014 (0.014)\tData 0.007 (0.007)\tLoss 0.0064 (0.0064)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.45 sec\n",
      "Epoch: [10][0/25]\tTime 0.015 (0.015)\tData 0.006 (0.006)\tLoss 0.0053 (0.0053)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "[10] test metrics:{\"loss\": 0.11596598851680756, \"error\": 0.030999996662139893}\n",
      "Learning Rate : 0.01\n",
      "Epoch Time: 0.57 sec\n",
      "Epoch: [11][0/25]\tTime 0.018 (0.018)\tData 0.007 (0.007)\tLoss 0.0039 (0.0039)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.44 sec\n",
      "Epoch: [12][0/25]\tTime 0.015 (0.015)\tData 0.007 (0.007)\tLoss 0.0031 (0.0031)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [13][0/25]\tTime 0.013 (0.013)\tData 0.006 (0.006)\tLoss 0.0023 (0.0023)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.42 sec\n",
      "Epoch: [14][0/25]\tTime 0.016 (0.016)\tData 0.007 (0.007)\tLoss 0.0039 (0.0039)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [15][0/25]\tTime 0.015 (0.015)\tData 0.007 (0.007)\tLoss 0.0025 (0.0025)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "[15] test metrics:{\"loss\": 0.11555922675132752, \"error\": 0.029999996662139893}\n",
      "Learning Rate : 0.01\n",
      "Epoch Time: 0.58 sec\n",
      "Epoch: [16][0/25]\tTime 0.015 (0.015)\tData 0.007 (0.007)\tLoss 0.0027 (0.0027)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [17][0/25]\tTime 0.015 (0.015)\tData 0.007 (0.007)\tLoss 0.0029 (0.0029)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [18][0/25]\tTime 0.015 (0.015)\tData 0.006 (0.006)\tLoss 0.0020 (0.0020)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.42 sec\n",
      "Epoch: [19][0/25]\tTime 0.015 (0.015)\tData 0.006 (0.006)\tLoss 0.0021 (0.0021)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [20][0/25]\tTime 0.014 (0.014)\tData 0.007 (0.007)\tLoss 0.0019 (0.0019)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "[20] test metrics:{\"loss\": 0.11719665408134461, \"error\": 0.029999996662139893}\n",
      "Learning Rate : 0.01\n",
      "Epoch Time: 0.57 sec\n",
      "Epoch: [21][0/25]\tTime 0.014 (0.014)\tData 0.007 (0.007)\tLoss 0.0024 (0.0024)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [22][0/25]\tTime 0.016 (0.016)\tData 0.007 (0.007)\tLoss 0.0017 (0.0017)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [23][0/25]\tTime 0.014 (0.014)\tData 0.007 (0.007)\tLoss 0.0016 (0.0016)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [24][0/25]\tTime 0.015 (0.015)\tData 0.007 (0.007)\tLoss 0.0011 (0.0011)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch Time: 0.43 sec\n",
      "Epoch: [25][0/25]\tTime 0.015 (0.015)\tData 0.006 (0.006)\tLoss 0.0014 (0.0014)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "[25] test metrics:{\"loss\": 0.12105911564826966, \"error\": 0.029999996662139893}\n",
      "Learning Rate : 0.01\n",
      "Epoch Time: 0.57 sec\n",
      "Pure training time: 11.189999999999998 sec\n"
     ]
    }
   ],
   "source": [
    "%run main_merged.py --dataset lacuna10 --model resnet --dataroot=data/lacuna10/ --filters 1 --lr 0.01 \\\n",
    "--resume checkpoints/lacuna100_resnet_1_0_forget_None_lr_0_1_bs_128_ls_ce_wd_0_0005_seed_1_30.pt --disable-bn \\\n",
    "--weight-decay 5e-4 --batch-size 128 --epochs 26 \\\n",
    "--forget-class 5 --num-to-forget 100 --seed 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dict={}\n",
    "training_epochs=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dict['epoch']=training_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Parameters: 11175178\n"
     ]
    }
   ],
   "source": [
    "parameter_count(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loads checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "model0 = copy.deepcopy(model)\n",
    "\n",
    "arch = args.model \n",
    "filters=args.filters\n",
    "arch_filters = arch +'_'+ str(filters).replace('.','_')\n",
    "augment = False\n",
    "dataset = args.dataset\n",
    "class_to_forget = args.forget_class\n",
    "init_checkpoint = f\"checkpoints/{args.name}_init.pt\"\n",
    "num_classes=args.num_classes\n",
    "num_to_forget = args.num_to_forget\n",
    "num_total = len(train_loader.dataset)\n",
    "num_to_retain = num_total - 4000#num_to_forget\n",
    "seed = args.seed\n",
    "unfreeze_start = None\n",
    "\n",
    "learningrate=f\"lr_{str(args.lr).replace('.','_')}\"\n",
    "batch_size=f\"_bs_{str(args.batch_size)}\"\n",
    "lossfn=f\"_ls_{args.lossfn}\"\n",
    "wd=f\"_wd_{str(args.weight_decay).replace('.','_')}\"\n",
    "seed_name=f\"_seed_{args.seed}_\"\n",
    "\n",
    "num_tag = '' if num_to_forget is None else f'_num_{num_to_forget}'\n",
    "unfreeze_tag = '_' if unfreeze_start is None else f'_unfreeze_from_{unfreeze_start}_'\n",
    "augment_tag = '' if not augment else f'augment_'\n",
    "\n",
    "m_name = f'checkpoints/{dataset}_{arch_filters}_forget_None{unfreeze_tag}{augment_tag}{learningrate}{batch_size}{lossfn}{wd}{seed_name}{training_epochs}.pt'\n",
    "m0_name = f'checkpoints/{dataset}_{arch_filters}_forget_{class_to_forget}{num_tag}{unfreeze_tag}{augment_tag}{learningrate}{batch_size}{lossfn}{wd}{seed_name}{training_epochs}.pt'\n",
    "\n",
    "model.load_state_dict(torch.load(m_name))\n",
    "model0.load_state_dict(torch.load(m0_name))\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "model0.cuda()\n",
    "\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.data0 = p.data.clone()\n",
    "for p in model0.parameters():\n",
    "    p.data0 = p.data.clone()\n",
    "\n",
    "teacher = copy.deepcopy(model)\n",
    "student = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confuse mode: False\n",
      "split mode: train\n",
      "confuse mode: False\n",
      "split mode: train\n",
      "Replacing indexes [1781 1858 1615 1665 1816 1663 1840 1828 1767 1756 1664 1703 1724 1915\n",
      " 1910 1660 1722 1871 1666 1626 1886 1758 1736 1909 1764 1800 1872 1607\n",
      " 1606 1830 1854 1622 1752 1621 1655 1757 1612 1708 1668 1744 1770 1878\n",
      " 1659 1734 1831 1692 1775 1867 1674 1681 1888 1859 1864 1652 1733 1776\n",
      " 1656 1690 1848 1617 1601 1608 1750 1806 1809 1740 1817 1794 1605 1633\n",
      " 1880 1634 1812 1815 1863 1737 1645 1701 1866 1726 1798 1838 1799 1822\n",
      " 1720 1845 1735 1673 1913 1904 1716 1855 1629 1697 1620 1646 1813 1862\n",
      " 1912 1689]\n"
     ]
    }
   ],
   "source": [
    "train_loader_full, valid_loader_full, test_loader_full   = datasets.get_loaders(dataset, batch_size=args.batch_size, seed=seed, root=args.dataroot, augment=False, shuffle=True)\n",
    "marked_loader, _, _  = datasets.get_loaders(dataset, class_to_replace=class_to_forget, num_indexes_to_replace=num_to_forget, only_mark=True, batch_size=1, seed=seed, root=args.dataroot, augment=False, shuffle=True)\n",
    "\n",
    "def replace_loader_dataset(data_loader, dataset, batch_size=args.batch_size, seed=1, shuffle=True):\n",
    "    manual_seed(seed)\n",
    "    loader_args = {'num_workers': 0, 'pin_memory': False}\n",
    "    def _init_fn(worker_id):\n",
    "        np.random.seed(int(seed))\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size,num_workers=0,pin_memory=True,shuffle=shuffle)\n",
    "    \n",
    "forget_dataset = copy.deepcopy(marked_loader.dataset)\n",
    "marked = forget_dataset.targets < 0\n",
    "forget_dataset.data = forget_dataset.data[marked]\n",
    "forget_dataset.targets = - forget_dataset.targets[marked] - 1\n",
    "forget_loader = replace_loader_dataset(train_loader_full, forget_dataset, batch_size=512, seed=seed, shuffle=True)\n",
    "\n",
    "retain_dataset = copy.deepcopy(marked_loader.dataset)\n",
    "marked = retain_dataset.targets >= 0\n",
    "retain_dataset.data = retain_dataset.data[marked]\n",
    "retain_dataset.targets = retain_dataset.targets[marked]\n",
    "retain_loader = replace_loader_dataset(train_loader_full, retain_dataset, batch_size=256, seed=seed, shuffle=True)\n",
    "\n",
    "\n",
    "assert(len(forget_dataset) + len(retain_dataset) == len(train_loader_full.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dict['args']=args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "3100\n",
      "1000\n",
      "3200\n",
      "{0: 320, 1: 320, 2: 320, 3: 320, 4: 320, 5: 320, 6: 320, 7: 320, 8: 320, 9: 320}\n"
     ]
    }
   ],
   "source": [
    "print (len(forget_loader.dataset))\n",
    "print (len(retain_loader.dataset))\n",
    "print (len(test_loader_full.dataset))\n",
    "print (len(train_loader_full.dataset))\n",
    "from collections import Counter\n",
    "print(dict(Counter(train_loader_full.dataset.targets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCRUB Forgetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.optim = 'sgd'\n",
    "args.gamma = 0.99\n",
    "args.alpha = 0.001\n",
    "args.beta = 0.99\n",
    "args.smoothing = 0.0\n",
    "args.msteps = 4\n",
    "args.clip = 0.2\n",
    "args.sstart = 4\n",
    "args.kd_T = 4\n",
    "args.distill = 'kd'\n",
    "\n",
    "args.sgda_batch_size = 32\n",
    "args.del_batch_size = 32\n",
    "args.sgda_epochs = 3\n",
    "args.sgda_learning_rate = 0.005\n",
    "args.lr_decay_epochs = [3,5,9]\n",
    "args.lr_decay_rate = 0.1\n",
    "args.sgda_weight_decay = 5e-4\n",
    "args.sgda_momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t = copy.deepcopy(teacher)\n",
    "model_s = copy.deepcopy(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is from https://github.com/ojus1/SmoothedGradientDescentAscent/blob/main/SGDA.py\n",
    "#For SGDA smoothing\n",
    "beta = 0.1\n",
    "def avg_fn(averaged_model_parameter, model_parameter, num_averaged): return (\n",
    "    1 - beta) * averaged_model_parameter + beta * model_parameter\n",
    "swa_model = torch.optim.swa_utils.AveragedModel(\n",
    "    model_s, avg_fn=avg_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_list = nn.ModuleList([])\n",
    "module_list.append(model_s)\n",
    "trainable_list = nn.ModuleList([])\n",
    "trainable_list.append(model_s)\n",
    "\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_div = DistillKL(args.kd_T)\n",
    "criterion_kd = DistillKL(args.kd_T)\n",
    "\n",
    "\n",
    "criterion_list = nn.ModuleList([])\n",
    "criterion_list.append(criterion_cls)    # classification loss\n",
    "criterion_list.append(criterion_div)    # KL divergence loss, original knowledge distillation\n",
    "criterion_list.append(criterion_kd)     # other knowledge distillation loss\n",
    "\n",
    "# optimizer\n",
    "if args.optim == \"sgd\":\n",
    "    optimizer = optim.SGD(trainable_list.parameters(),\n",
    "                          lr=args.sgda_learning_rate,\n",
    "                          momentum=args.sgda_momentum,\n",
    "                          weight_decay=args.sgda_weight_decay)\n",
    "elif args.optim == \"adam\": \n",
    "    optimizer = optim.Adam(trainable_list.parameters(),\n",
    "                          lr=args.sgda_learning_rate,\n",
    "                          weight_decay=args.sgda_weight_decay)\n",
    "elif args.optim == \"rmsp\":\n",
    "    optimizer = optim.RMSprop(trainable_list.parameters(),\n",
    "                          lr=args.sgda_learning_rate,\n",
    "                          momentum=args.sgda_momentum,\n",
    "                          weight_decay=args.sgda_weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_list.append(model_t)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    module_list.cuda()\n",
    "    criterion_list.cuda()\n",
    "    import torch.backends.cudnn as cudnn\n",
    "    cudnn.benchmark = True\n",
    "    swa_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> SCRUB unlearning ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zihao/anaconda3/envs/zihao/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Acc@1 95.935 \n",
      "maximize loss: -17.75\t minimize loss: 0.17\t train_acc: 95.93548583984375\n",
      "==> SCRUB unlearning ...\n",
      " * Acc@1 96.323 \n",
      "maximize loss: -52.85\t minimize loss: 0.28\t train_acc: 96.32258605957031\n",
      "==> SCRUB unlearning ...\n",
      " * Acc@1 91.710 \n",
      "maximize loss: -186.09\t minimize loss: 1.52\t train_acc: 91.70967864990234\n"
     ]
    }
   ],
   "source": [
    "acc_rs = []\n",
    "acc_fs = []\n",
    "acc_ts = []\n",
    "acc_vs = []\n",
    "for epoch in range(1, args.sgda_epochs + 1):\n",
    "\n",
    "    lr = sgda_adjust_learning_rate(epoch, args, optimizer)\n",
    "\n",
    "    print(\"==> SCRUB unlearning ...\")\n",
    "\n",
    "    acc_r, acc5_r, loss_r = validate(retain_loader, model_s, criterion_cls, args, True, prefix=\"train_lacuna10_selective_resnet\")\n",
    "    acc_f, acc5_f, loss_f = validate(forget_loader, model_s, criterion_cls, args, True, prefix=\"forget_lacuna10_selective_resnet\")\n",
    "    acc_v, acc5_v, loss_v = validate(valid_loader_full, model_s, criterion_cls, args, True)\n",
    "    acc_rs.append(100-acc_r.item())\n",
    "    acc_fs.append(100-acc_f.item())\n",
    "    acc_vs.append(100-acc_v.item())\n",
    "\n",
    "    maximize_loss = 0\n",
    "    if epoch <= args.msteps:\n",
    "        maximize_loss = train_distill(epoch, forget_loader, module_list, swa_model, criterion_list, optimizer, args, \"maximize\")\n",
    "    train_acc, train_loss = train_distill(epoch, retain_loader, module_list, swa_model, criterion_list, optimizer, args, \"minimize\")\n",
    "    if epoch >= args.sstart:\n",
    "        swa_model.update_parameters(model_s)\n",
    "\n",
    "    \n",
    "    print (\"maximize loss: {:.2f}\\t minimize loss: {:.2f}\\t train_acc: {}\".format(maximize_loss, train_loss, train_acc))\n",
    "acc_r, acc5_r, loss_r = validate(retain_loader, model_s, criterion_cls, args, True)\n",
    "acc_f, acc5_f, loss_f = validate(forget_loader, model_s, criterion_cls, args, True)\n",
    "acc_v, acc5_v, loss_v = validate(valid_loader_full, model_s, criterion_cls, args, True)\n",
    "acc_rs.append(100-acc_r.item())\n",
    "acc_fs.append(100-acc_f.item())\n",
    "acc_vs.append(100-acc_v.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "indices = list(range(0,len(acc_rs)))\n",
    "plt.plot(indices, acc_rs, marker='*', alpha=1, label='retain-set')\n",
    "plt.plot(indices, acc_fs, marker='o', alpha=1, label='forget-set')\n",
    "plt.plot(indices, acc_vs, marker='.', alpha=1, label='valid-set')\n",
    "plt.legend(prop={'size': 14})\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.title('SCRUB retain-, valid- and forget- set error',size=18)\n",
    "plt.xlabel('epoch',size=14)\n",
    "plt.ylabel('error',size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original_Model_D_r -> Loss:0.001, Error:0.0\n",
      "Original_Model_D_f -> Loss:0.001, Error:0.0\n",
      "Original_Model_D_t -> Loss:0.114, Error:0.028\n"
     ]
    }
   ],
   "source": [
    "m_D_r_activations,m_D_r_predictions=activations_predictions(copy.deepcopy(model),copy.deepcopy(retain_loader),'Original_Model_D_r')\n",
    "m_D_f_activations,m_D_f_predictions=activations_predictions(copy.deepcopy(model),copy.deepcopy(forget_loader),'Original_Model_D_f')\n",
    "m_D_t_activations,m_D_t_predictions=activations_predictions(copy.deepcopy(model),copy.deepcopy(test_loader_full),'Original_Model_D_t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain_Model_D_r -> Loss:0.001, Error:0.0\n",
      "Retrain_Model_D_f -> Loss:0.044, Error:0.03\n",
      "Retrain_Model_D_t -> Loss:0.117, Error:0.03\n"
     ]
    }
   ],
   "source": [
    "m0_D_r_activations,m0_D_r_predictions=activations_predictions(copy.deepcopy(model0),copy.deepcopy(retain_loader),'Retrain_Model_D_r')\n",
    "m0_D_f_activations,m0_D_f_predictions=activations_predictions(copy.deepcopy(model0),copy.deepcopy(forget_loader),'Retrain_Model_D_f')\n",
    "m0_D_t_activations,m0_D_t_predictions=activations_predictions(copy.deepcopy(model0),copy.deepcopy(test_loader_full),'Retrain_Model_D_t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCRUB_D_r -> Loss:0.387, Error:0.05935483870967742\n",
      "SCRUB_D_f -> Loss:2.827, Error:0.04\n",
      "SCRUB_D_t -> Loss:2.371, Error:0.095\n"
     ]
    }
   ],
   "source": [
    "ntk_D_r_activations,ntk_D_r_predictions=activations_predictions(copy.deepcopy(model_s),copy.deepcopy(retain_loader),'SCRUB_D_r')\n",
    "ntk_D_f_activations,ntk_D_f_predictions=activations_predictions(copy.deepcopy(model_s),copy.deepcopy(forget_loader),'SCRUB_D_f')\n",
    "ntk_D_t_activations,ntk_D_t_predictions=activations_predictions(copy.deepcopy(model_s),copy.deepcopy(test_loader_full),'SCRUB_D_t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fisher Forgetting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelf = copy.deepcopy(model)\n",
    "modelf0 = copy.deepcopy(model0)\n",
    "\n",
    "for p in itertools.chain(modelf.parameters(), modelf0.parameters()):\n",
    "    p.data0 = copy.deepcopy(p.data.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian(dataset, model):\n",
    "    model.eval()\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for p in model.parameters():\n",
    "        p.grad_acc = 0\n",
    "        p.grad2_acc = 0\n",
    "    \n",
    "    for data, orig_target in tqdm(train_loader):\n",
    "        data, orig_target = data.to(args.device), orig_target.to(args.device)\n",
    "        output = model(data)\n",
    "        prob = F.softmax(output, dim=-1).data\n",
    "\n",
    "        for y in range(output.shape[1]):\n",
    "            target = torch.empty_like(orig_target).fill_(y)\n",
    "            loss = loss_fn(output, target)\n",
    "            model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            for p in model.parameters():\n",
    "                if p.requires_grad:\n",
    "                    p.grad_acc += (orig_target == target).float() * p.grad.data\n",
    "                    p.grad2_acc += prob[:, y] * p.grad.data.pow(2)\n",
    "    for p in model.parameters():\n",
    "        p.grad_acc /= len(train_loader)\n",
    "        p.grad2_acc /= len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3100/3100 [03:20<00:00, 15.50it/s]\n"
     ]
    }
   ],
   "source": [
    "hessian(retain_loader.dataset, modelf)\n",
    "#hessian(retain_loader.dataset, modelf0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_var(p, is_base_dist=False, alpha=3e-6):\n",
    "    var = copy.deepcopy(1./(p.grad2_acc+1e-8))\n",
    "    var = var.clamp(max=1e3)\n",
    "    if p.size(0) == num_classes:\n",
    "        var = var.clamp(max=1e2)\n",
    "    var = alpha * var\n",
    "    \n",
    "    if p.ndim > 1:\n",
    "        var = var.mean(dim=1, keepdim=True).expand_as(p).clone()\n",
    "    if not is_base_dist:\n",
    "        mu = copy.deepcopy(p.data0.clone())\n",
    "    else:\n",
    "        mu = copy.deepcopy(p.data0.clone())\n",
    "    if p.size(0) == num_classes and num_to_forget is None:\n",
    "        mu[class_to_forget] = 0\n",
    "        var[class_to_forget] = 0.0001\n",
    "    if p.size(0) == num_classes:\n",
    "        # Last layer\n",
    "        var *= 10\n",
    "    elif p.ndim == 1:\n",
    "        # BatchNorm\n",
    "        var *= 10\n",
    "#         var*=1\n",
    "    return mu, var\n",
    "\n",
    "def kl_divergence_fisher(mu0, var0, mu1, var1):\n",
    "    return ((mu1 - mu0).pow(2)/var0 + var1/var0 - torch.log(var1/var0) - 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_dir = []\n",
    "alpha = 1e-7\n",
    "torch.manual_seed(seed)\n",
    "for i, p in enumerate(modelf.parameters()):\n",
    "    mu, var = get_mean_var(p, False, alpha=alpha)\n",
    "    p.data = mu + var.sqrt() * torch.empty_like(p.data0).normal_()\n",
    "    fisher_dir.append(var.sqrt().view(-1).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher Noise in Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher_D_r -> Loss:0.005, Error:0.0\n",
      "Fisher_D_f -> Loss:0.006, Error:0.0\n",
      "Fisher_D_t -> Loss:0.121, Error:0.033\n"
     ]
    }
   ],
   "source": [
    "fisher_D_r_activations,fisher_D_r_predictions=activations_predictions(copy.deepcopy(modelf),copy.deepcopy(retain_loader),'Fisher_D_r')\n",
    "fisher_D_f_activations,fisher_D_f_predictions=activations_predictions(copy.deepcopy(modelf),copy.deepcopy(forget_loader),'Fisher_D_f')\n",
    "fisher_D_t_activations,fisher_D_t_predictions=activations_predictions(copy.deepcopy(modelf),copy.deepcopy(test_loader_full),'Fisher_D_t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information in the Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/25]\tTime 0.040 (0.040)\tData 0.008 (0.008)\tLoss 0.0022 (0.0022)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch: [1][0/25]\tTime 0.014 (0.014)\tData 0.007 (0.007)\tLoss 0.0016 (0.0016)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch: [2][0/25]\tTime 0.018 (0.018)\tData 0.008 (0.008)\tLoss 0.0015 (0.0015)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch: [3][0/25]\tTime 0.014 (0.014)\tData 0.007 (0.007)\tLoss 0.0011 (0.0011)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch: [4][0/25]\tTime 0.019 (0.019)\tData 0.011 (0.011)\tLoss 0.0034 (0.0034)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch: [5][0/25]\tTime 0.027 (0.027)\tData 0.015 (0.015)\tLoss 0.0012 (0.0012)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch: [6][0/25]\tTime 0.015 (0.015)\tData 0.007 (0.007)\tLoss 0.0014 (0.0014)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch: [7][0/25]\tTime 0.016 (0.016)\tData 0.007 (0.007)\tLoss 0.0017 (0.0017)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch: [8][0/25]\tTime 0.019 (0.019)\tData 0.010 (0.010)\tLoss 0.0012 (0.0012)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n",
      "Epoch: [9][0/25]\tTime 0.016 (0.016)\tData 0.007 (0.007)\tLoss 0.0009 (0.0009)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
      " * Acc@1 100.000 Acc@5 100.000\n"
     ]
    }
   ],
   "source": [
    "model_ft = copy.deepcopy(model)\n",
    "retain_loader = replace_loader_dataset(train_loader_full,retain_dataset, seed=seed, batch_size=args.batch_size, shuffle=True)    \n",
    "finetune(model_ft, retain_loader, epochs=10, quiet=True, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune_D_r -> Loss:0.001, Error:0.0\n",
      "Finetune_D_f -> Loss:0.001, Error:0.0\n",
      "Finetune_D_t -> Loss:0.112, Error:0.03\n"
     ]
    }
   ],
   "source": [
    "finetune_D_r_activations,finetune_D_r_predictions=activations_predictions(copy.deepcopy(model_ft),copy.deepcopy(retain_loader),'Finetune_D_r')\n",
    "finetune_D_f_activations,finetune_D_f_predictions=activations_predictions(copy.deepcopy(model_ft),copy.deepcopy(forget_loader),'Finetune_D_f')\n",
    "finetune_D_t_activations,finetune_D_t_predictions=activations_predictions(copy.deepcopy(model_ft),copy.deepcopy(test_loader_full),'Finetune_D_t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007327129651447229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ->\tFull test error: 2.80%\tForget error: 0.00%\tRetain error: 0.00%\tFine-tune time: 1 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune ->\tFull test error: 3.00%\tForget error: 0.00%\tRetain error: 0.00%\tFine-tune time: 1 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher ->\tFull test error: 3.30%\tForget error: 0.00%\tRetain error: 0.00%\tFine-tune time: 100 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain ->\tFull test error: 3.00%\tForget error: 3.00%\tRetain error: 0.00%\tFine-tune time: 100 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCRUB ->\tFull test error: 9.50%\tForget error: 4.00%\tRetain error: 5.94%\tFine-tune time: 35 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "try: readouts\n",
    "except: readouts = {}\n",
    "\n",
    "thresh=log_dict['Original_Model_D_f_loss']+1e-5\n",
    "print(thresh)\n",
    "readouts[\"e\"] = all_readouts(copy.deepcopy(model),thresh,'Original')\n",
    "readouts[\"a\"] = all_readouts(copy.deepcopy(model_ft),thresh,'Finetune')\n",
    "readouts[\"b\"] = all_readouts(copy.deepcopy(modelf),thresh,'Fisher')\n",
    "readouts[\"d\"] = all_readouts(copy.deepcopy(model0),thresh,'Retrain')\n",
    "readouts[\"d\"] = all_readouts(copy.deepcopy(model_s),thresh,'SCRUB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16127/2828292684.py:82: RuntimeWarning: divide by zero encountered in log\n",
      "  sns.distplot(np.log(X_r[Y_r==1]).reshape(-1), kde=False, norm_hist=True, rug=False, label='retain', ax=plt)\n",
      "/tmp/ipykernel_16127/2828292684.py:82: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(np.log(X_r[Y_r==1]).reshape(-1), kde=False, norm_hist=True, rug=False, label='retain', ax=plt)\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "cannot convert float infinity to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#fig, ax = plt.subplots(5,1,figsize=(9,20))\u001b[39;00m\n\u001b[1;32m      2\u001b[0m ax \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m \u001b[43mplot_entropy_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_s\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mretain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mforget_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSCRUB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43max\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m plot_entropy_dist(copy\u001b[38;5;241m.\u001b[39mdeepcopy(model),retain_loader,forget_loader,test_loader_full, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m, ax[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      5\u001b[0m plot_entropy_dist(copy\u001b[38;5;241m.\u001b[39mdeepcopy(model0),retain_loader,forget_loader,test_loader_full, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretrain\u001b[39m\u001b[38;5;124m'\u001b[39m, ax[\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[6], line 82\u001b[0m, in \u001b[0;36mplot_entropy_dist\u001b[0;34m(model, retain_loader, forget_loader, test_loader_full, title, ax)\u001b[0m\n\u001b[1;32m     78\u001b[0m X_f, Y_f, X_r, Y_r \u001b[38;5;241m=\u001b[39m get_membership_attack_data(retain_loader,forget_loader,test_loader_full, model)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m#np.savetxt('retain_prob.txt', X_r[Y_r==1])\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m#np.savetxt('forget_prob.txt', X_f)\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m#np.savetxt('test_prob.txt', X_r[Y_r==0])\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_r\u001b[49m\u001b[43m[\u001b[49m\u001b[43mY_r\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_hist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m sns\u001b[38;5;241m.\u001b[39mdistplot(np\u001b[38;5;241m.\u001b[39mlog(X_r[Y_r\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, norm_hist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, ax\u001b[38;5;241m=\u001b[39mplt)\n\u001b[1;32m     84\u001b[0m sns\u001b[38;5;241m.\u001b[39mdistplot(np\u001b[38;5;241m.\u001b[39mlog(X_f)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, norm_hist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforget\u001b[39m\u001b[38;5;124m'\u001b[39m, ax\u001b[38;5;241m=\u001b[39mplt)\n",
      "File \u001b[0;32m~/anaconda3/envs/zihao/lib/python3.10/site-packages/seaborn/distributions.py:2481\u001b[0m, in \u001b[0;36mdistplot\u001b[0;34m(a, bins, hist, kde, rug, fit, hist_kws, kde_kws, rug_kws, fit_kws, color, vertical, norm_hist, axlabel, label, ax, x)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hist:\n\u001b[1;32m   2480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bins \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2481\u001b[0m         bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[43m_freedman_diaconis_bins\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m   2482\u001b[0m     hist_kws\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.4\u001b[39m)\n\u001b[1;32m   2483\u001b[0m     hist_kws\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdensity\u001b[39m\u001b[38;5;124m\"\u001b[39m, norm_hist)\n",
      "File \u001b[0;32m~/anaconda3/envs/zihao/lib/python3.10/site-packages/seaborn/distributions.py:2387\u001b[0m, in \u001b[0;36m_freedman_diaconis_bins\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   2385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39msqrt(a\u001b[38;5;241m.\u001b[39msize))\n\u001b[1;32m   2386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOverflowError\u001b[0m: cannot convert float infinity to integer"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fig, ax = plt.subplots(5,1,figsize=(9,20))\n",
    "ax = [0,0,0,0,0]\n",
    "plot_entropy_dist(copy.deepcopy(model_s),retain_loader,forget_loader,test_loader_full, 'SCRUB',ax[4])\n",
    "plot_entropy_dist(copy.deepcopy(model),retain_loader,forget_loader,test_loader_full, 'original', ax[0])\n",
    "plot_entropy_dist(copy.deepcopy(model0),retain_loader,forget_loader,test_loader_full, 'retrain', ax[1])\n",
    "plot_entropy_dist(copy.deepcopy(model_ft),retain_loader,forget_loader,test_loader_full, 'finetuned',ax[2])\n",
    "plot_entropy_dist(copy.deepcopy(modelf),retain_loader,forget_loader,test_loader_full, 'fisher',ax[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
